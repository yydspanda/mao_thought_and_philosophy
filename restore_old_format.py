# restore_old_format.py
import json
import os
import re
from pathlib import Path
from collections import defaultdict

# ======================= ç”¨æˆ·é…ç½® =======================
# â—ï¸ è¯·ç¡®ä¿è¿™ä¸ªè·¯å¾„æŒ‡å‘ä½ æƒ³è¦æ¸…ç†çš„ä¹¦ç±çš„è¾“å‡ºç›®å½•
BOOK_DIR = Path("output/æ¯›æ³½ä¸œé€‰é›†ä¸€è‡³ä¸ƒå·") 
# ==========================================================

CHAPTERS_DIR = BOOK_DIR / "chapters"
JSON_PATH = BOOK_DIR / "knowledge_graph.json"

# å®šä¹‰å“ªäº›å­—ç¬¦æ˜¯â€œå¥½â€çš„ï¼ˆæ—§æ ¼å¼åŒ…å«ï¼Œæ–°æ ¼å¼æ²¡æœ‰ï¼‰
# æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ é™¤ä¸åŒ…å«è¿™äº›å­—ç¬¦çš„é‡å¤é¡¹
GOOD_CHARS = {'ã€Š', 'ã€‹', 'â€œ', 'â€', '"'}

def create_base_name(filename):
    """åˆ›å»ºä¸€ä¸ªç”¨äºæ¯”è¾ƒçš„â€œè£¸åâ€ï¼Œå³å»æ‰æ‰€æœ‰ç‰¹æ®Šç¬¦å·å’Œåç¼€"""
    name_no_ext = filename.rsplit('.', 1)[0]
    return re.sub(r'[ã€Šã€‹â€œâ€"]', '', name_no_ext)

def clean_duplicate_files():
    """æ‰«æ chapters ç›®å½•ï¼Œåˆ é™¤æ–°çš„ã€ä¸å¸¦ç¬¦å·çš„é‡å¤æ–‡ä»¶"""
    print(f"ğŸ§¹ [1/3] æ­£åœ¨æ‰«æç›®å½•: {CHAPTERS_DIR}")
    if not CHAPTERS_DIR.exists():
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° chapters ç›®å½•ï¼Œè¯·æ£€æŸ¥ BOOK_DIR é…ç½®ã€‚")
        return []

    # 1. æŒ‰â€œè£¸åâ€å¯¹æ‰€æœ‰æ–‡ä»¶è¿›è¡Œåˆ†ç»„
    grouped_files = defaultdict(list)
    for file_path in CHAPTERS_DIR.glob("*.md"):
        base_name = create_base_name(file_path.name)
        grouped_files[base_name].append(file_path)

    # 2. æ‰¾å‡ºé‡å¤ç»„ï¼Œå¹¶åˆ é™¤â€œåâ€æ–‡ä»¶
    files_to_delete = []
    for base_name, file_list in grouped_files.items():
        if len(file_list) > 1:  # è¿™æ˜¯ä¸€ä¸ªé‡å¤ç»„
            print(f"\n   å‘ç°é‡å¤ç»„: {base_name}")
            for file_path in file_list:
                # å¦‚æœæ–‡ä»¶åä¸­ä¸åŒ…å«ä»»ä½•â€œå¥½â€å­—ç¬¦ï¼Œé‚£å®ƒå°±æ˜¯æ–°ç”Ÿæˆçš„â€œåâ€æ–‡ä»¶
                if not any(char in file_path.name for char in GOOD_CHARS):
                    files_to_delete.append(file_path)
                    print(f"      - æ ‡è®°åˆ é™¤: {file_path.name} (æ–°æ ¼å¼)")
                else:
                    print(f"      - ä¿ç•™: {file_path.name} (æ—§æ ¼å¼)")

    # 3. æ‰§è¡Œåˆ é™¤
    deleted_filenames = []
    if not files_to_delete:
        print("âœ… æ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„é‡å¤æ–‡ä»¶ã€‚")
        return []

    print("\nğŸ—‘ï¸  å¼€å§‹æ‰§è¡Œåˆ é™¤...")
    for file_path in files_to_delete:
        try:
            deleted_filenames.append(file_path.name)
            os.remove(file_path)
            print(f"   - å·²åˆ é™¤: {file_path.name}")
        except OSError as e:
            print(f"   - âŒ åˆ é™¤å¤±è´¥: {file_path.name}, é”™è¯¯: {e}")
    
    print(f"âœ… æ–‡ä»¶æ¸…ç†å®Œæ¯•ï¼Œå…±åˆ é™¤ {len(deleted_filenames)} ä¸ªæ–‡ä»¶ã€‚")
    return deleted_filenames

def clean_json_memory(deleted_filenames):
    """è¯»å– JSON æ–‡ä»¶ï¼Œæ¸…é™¤æ‰€æœ‰ä¸è¢«åˆ é™¤æ–‡ä»¶ç›¸å…³çš„å¼•ç”¨å’Œæ¦‚å¿µ"""
    print(f"\nğŸ§  [2/3] æ­£åœ¨æ¸…ç†çŸ¥è¯†å›¾è°±: {JSON_PATH}")
    if not deleted_filenames:
        print("âœ… æ— éœ€æ¸…ç†çŸ¥è¯†å›¾è°±ã€‚")
        return
        
    if not JSON_PATH.exists():
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° knowledge_graph.json æ–‡ä»¶ã€‚")
        return

    # å°†æ–‡ä»¶åè½¬æ¢ä¸º JSON ä¸­ä½¿ç”¨çš„ "link_name" (æ— åç¼€)
    purge_link_names = {name.rsplit('.', 1)[0] for name in deleted_filenames}
    
    with open(JSON_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)

    concepts = data.get("concepts", {})
    appearances = data.get("appearances", {})
    
    # 1. æ¸…ç†å‡ºå¤„ (appearances)
    concepts_to_fully_remove = set()
    for concept_name, links in appearances.items():
        # è¿‡æ»¤åˆ—è¡¨ï¼Œåªä¿ç•™ä¸è¯¥è¢«åˆ é™¤çš„é“¾æ¥
        original_count = len(links)
        appearances[concept_name] = [link for link in links if link not in purge_link_names]
        
        if len(appearances[concept_name]) < original_count:
            print(f"   - æ¸…ç†å¼•ç”¨: æ¦‚å¿µ [{concept_name}] ä¸­ç§»é™¤äº†ä¸æ–°æ–‡ä»¶çš„å…³è”ã€‚")

        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æ¦‚å¿µå˜æˆäº†â€œå­¤å„¿â€
        if not appearances[concept_name]:
            concepts_to_fully_remove.add(concept_name)
            print(f"      - å‘ç°å­¤å„¿æ¦‚å¿µ: [{concept_name}] å·²æ²¡æœ‰ä»»ä½•å¼•ç”¨ï¼Œå°†è¢«å½»åº•åˆ é™¤ã€‚")

    # 3. å½»åº•åˆ é™¤å­¤å„¿æ¦‚å¿µ
    for concept_name in concepts_to_fully_remove:
        if concept_name in appearances:
            del appearances[concept_name]
        if concept_name in concepts:
            del concepts[concept_name]
    
    # 4. å†™å› JSON æ–‡ä»¶
    with open(JSON_PATH, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print("âœ… çŸ¥è¯†å›¾è°±æ¸…ç†å®Œæ¯•ã€‚")

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰§è¡ŒçŸ¥è¯†åº“å›æ»šä¸æ¸…ç†ç¨‹åº...")
    
    # ç¬¬ä¸€æ­¥ï¼šæ¸…ç†æ–‡ä»¶
    deleted_files = clean_duplicate_files()
    
    # ç¬¬äºŒæ­¥ï¼šæ¸…ç†JSON
    clean_json_memory(deleted_files)
    
    print("\nğŸ‰ [3/3] å…¨éƒ¨æ¸…ç†å·¥ä½œå®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. æ£€æŸ¥ `workflow.py` ä¸­çš„ `sanitize_filename` å‡½æ•°æ˜¯å¦å·²æ¢å¤åˆ°æ—§ç‰ˆã€‚")
    print("2. é‡æ–°è¿è¡Œä½ çš„ä¸»ç¨‹åº `main.py`ï¼Œå®ƒä¼šè‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„æ—§æ–‡ä»¶ï¼Œå¹¶ä¸ºä½ é‡æ–°ç”Ÿæˆè¢«åˆ é™¤çš„æ–‡ä»¶ï¼ˆè¿™æ¬¡ä¼šæ˜¯å¸¦ä¹¦åå·çš„å¥½ç‰ˆæœ¬ï¼‰ã€‚")
    print("3. æœ€åï¼Œé‡æ–°ç”Ÿæˆä¸€æ¬¡æ¦‚å¿µå¡ç‰‡ä»¥ç¡®ä¿é“¾æ¥æ­£ç¡®æ— è¯¯ã€‚")

if __name__ == "__main__":
    main()