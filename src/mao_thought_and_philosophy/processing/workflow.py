import datetime
import re
import sys
import time
from pathlib import Path

# ä¿æŒåŸæœ‰çš„å¯¼å…¥ä¸å˜
from .prompt_templates import get_user_prompt, get_system_prompt
from ..config import ASSETS_DIR, OUTPUT_DIR
from ..core.graph_builder import ConceptMemory
from ..core.llm_client import call_llm_json
from ..core.loader import read_epub_chapters_mao_selected


def sanitize_filename(name):
    # ... å®‰å…¨æ–‡ä»¶å
    name = name.replace('.html', '').replace('.xhtml', '')
    name = re.sub(r'[\\/*?:"<>|â€œâ€â€˜â€™\'"]', "", name)
    return name.strip()[:60]

def get_safe_title_from_chap(chapter_data):
    """è¾…åŠ©å‡½æ•°ï¼šä»ç« èŠ‚æ•°æ®ä¸­æå–å¹¶æ¸…æ´—æ ‡é¢˜"""
    raw = chapter_data.get('title', chapter_data['id'])
    return sanitize_filename(raw)


def wait_with_countdown(seconds, message="ç­‰å¾…ä¸­"):
    """
    å€’è®¡æ—¶è¾…åŠ©å‡½æ•°
    æ˜¾ç¤ºæ ¼å¼ï¼šâ³ ç­‰å¾…ä¸­: 00:29:59 ...
    """
    print(f"\nğŸ›‘ {message} (å…± {seconds / 60:.1f} åˆ†é’Ÿ)...")
    for remaining in range(seconds, 0, -1):
        mins, secs = divmod(remaining, 60)
        hours, mins = divmod(mins, 60)
        time_format = f"{hours:02d}:{mins:02d}:{secs:02d}"

        # ä½¿ç”¨ \r å›è½¦ç¬¦å®ç°å•è¡Œåˆ·æ–°ï¼Œä¸æ¢è¡Œ
        sys.stdout.write(f"\râ³ å€’è®¡æ—¶: {time_format}")
        sys.stdout.flush()
        time.sleep(1)
    print("\nâœ… ç­‰å¾…ç»“æŸï¼Œç»§ç»­æ‰§è¡Œï¼\n")


def generate_concept_cards(memory, output_dir: Path):
    """å°† JSON æ•°æ®è½¬åŒ–ä¸º Obsidian å¯è¯»çš„ Markdown æ¦‚å¿µå¡ç‰‡"""
    concepts_dir = output_dir / "concepts"
    concepts_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ“‡ æ­£åœ¨ç”Ÿæˆæ¦‚å¿µå¡ç‰‡è‡³: {concepts_dir}")

    for name, definition in memory.concepts.items():
        safe_name = sanitize_filename(name)
        if not safe_name:
            continue

        file_path = concepts_dir / f"{safe_name}.md"
        chapter_links = memory.appearances.get(name, [])
        # ç”ŸæˆåŒå‘é“¾æ¥åˆ—è¡¨
        backlinks = ", ".join([f"[[{link}]]" for link in chapter_links])

        content = f"""---
tags: [æ ¸å¿ƒæ¦‚å¿µ]
---

# {name}

### ğŸ“ å®šä¹‰
> {definition}

### ğŸ“š å‡ºç°ç« èŠ‚
{backlinks}
"""
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)

    print("âœ… æ¦‚å¿µå¡ç‰‡æ›´æ–°å®Œæ¯•")


def run_analysis(epub_filename: str):
    # 1. åŠ¨æ€æ„å»ºè·¯å¾„
    epub_path = ASSETS_DIR / epub_filename
    if not epub_path.exists():
        print(f"âŒ é”™è¯¯ï¼šåœ¨ {ASSETS_DIR} ä¸‹æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{epub_filename}")
        return
    book_title = epub_path.stem  # "æ¯›æ³½ä¸œé€‰é›†ä¸€è‡³ä¸ƒå·"
    safe_book_title = sanitize_filename(book_title)
    # ã€å…³é”®ã€‘ä¸ºè¿™æœ¬ä¹¦åˆ›å»ºç‹¬ç«‹çš„çŸ¥è¯†åº“ç›®å½•
    current_kb_dir = OUTPUT_DIR / safe_book_title
    chapters_dir = current_kb_dir / "chapters"

    current_kb_dir.mkdir(parents=True, exist_ok=True)
    chapters_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ“– æ­£åœ¨è§£æã€Š{book_title}ã€‹...")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {current_kb_dir}")

    # 2. åŠ è½½æ•°æ®
    current_system_prompt = get_system_prompt(book_title)
    # ã€æ ¸å¿ƒè°ƒç”¨ã€‘ä½¿ç”¨æ–°çš„åŠ è½½å™¨ï¼Œè·å–å¸¦å±‚çº§ï¼ˆå·ã€æ—¶æœŸï¼‰å’Œæ—¥æœŸçš„æ•°æ®
    chapters = read_epub_chapters_mao_selected(epub_path)
    # åŠ è½½é’ˆå¯¹è¿™æœ¬ä¹¦çš„è®°å¿†æ–‡ä»¶
    memory = ConceptMemory()
    json_path = current_kb_dir / "knowledge_graph.json"
    memory.load_from_file(json_path)

    print(f"ğŸ“š å…±è¯†åˆ«å‡º {len(chapters)} ä¸ªç« èŠ‚ã€‚")

    # =================================================================
    # å¯åŠ¨å»¶æ—¶ç­–ç•¥ (æŒ‰éœ€å¼€å¯)
    # print("ğŸš¦ ä¾æ®ç­–ç•¥ï¼Œç¨‹åºå°†åœ¨ 5 ç§’åå¼€å§‹å¤„ç†...")
    # wait_with_countdown(5, "å¯åŠ¨å»¶è¿Ÿ")
    # =================================================================

    # åˆå§‹åŒ–å…¨ä¹¦ç´¢å¼•å†…å®¹ (Markdown è¡¨æ ¼)
    # ã€æ–°å¢ã€‘å¢åŠ äº† å·ã€æ—¶æœŸã€æ—¥æœŸ åˆ—
    index_content = "# å…¨ä¹¦ç›®å½•ä¸ç´¢å¼•\n\n| åºå· | å·åˆ« | æ—¶æœŸ | ç« èŠ‚ | å‘è¡¨æ—¥æœŸ | æ ¸å¿ƒæ ‡ç­¾ | ä¸€å¥è¯æ€»ç»“ |\n|---|---|---|---|---|---|---|\n"

    # 3. é€ç« å¤„ç†
    for i, chap in enumerate(chapters):

        curr_safe_title = get_safe_title_from_chap(chap)
        # ç”Ÿæˆå¸¦åºå·çš„æ–‡ä»¶åï¼Œä¿è¯æ’åº
        file_name = f"{i + 1:03d}_{curr_safe_title}.md"
        file_path = chapters_dir / file_name
        # é“¾æ¥åï¼ˆç”¨äº Obsidian åŒé“¾ï¼‰
        link_name = f"{i + 1:03d}_{curr_safe_title}"
        # æå–å…ƒæ•°æ® (ä½¿ç”¨ .get æä¾›é»˜è®¤å€¼ï¼Œé˜²æ­¢æ—§æ•°æ®æŠ¥é”™)
        volume = chap.get('volume', 'æœªåˆ†ç±»')
        period = chap.get('period', 'æœªåˆ†ç±»')
        publish_date = chap.get('date', 'æœªçŸ¥')
        # =================================================================
        # æ–­ç‚¹ç»­ä¼ ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        # =================================================================
        if file_path.exists():
            print(f"â© [å·²å­˜åœ¨ï¼Œè·³è¿‡] {file_name}")
            try:
                # å°è¯•è¯»å–å·²å­˜åœ¨æ–‡ä»¶çš„ Frontmatter æˆ–å†…å®¹ï¼Œå¡«å…¥ç´¢å¼•è¡¨
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    # æ­£åˆ™æå–æ‘˜è¦
                    summary_match = re.search(r'> \*\*æ‘˜è¦\*\*ï¼š(.*?)\n', content)
                    summary = summary_match.group(1).strip() if summary_match else "ï¼ˆæ‘˜è¦è¯»å–å¤±è´¥ï¼‰"
                    # æ­£åˆ™æå–æ ‡ç­¾
                    tags_match = re.search(r'tags: \[(.*?)\]', content)
                    tags_str = tags_match.group(1) if tags_match else ""
                    tags_clean = tags_str.replace("'", "").replace('"', "")
                    tags_display = ", ".join([f"`{t.strip()}`" for t in tags_clean.split(',')][:3])
                    # æ„å»ºç´¢å¼•è¡Œ
                    link = f"[{curr_safe_title}](./chapters/{file_name})"
                    index_content += f"| {i + 1} | {volume} | {period} | {link} | {publish_date} | {tags_display} | {summary} |\n"
            except Exception:
                pass
            continue  # è·³è¿‡ï¼Œä¸”ä¸è¿›è¡Œç­‰å¾…
        # =================================================================
        # å¼€å§‹å¤„ç†æ–°ç« èŠ‚ï¼ˆæˆ–è¢«åˆ é™¤åé‡è·‘çš„ç« èŠ‚ï¼‰
        # =================================================================
        # ã€æ ¸å¿ƒæ­¥éª¤ã€‘é˜²æ­¢æ±¡æŸ“ï¼šå…ˆä»å†…å­˜ä¸­æŠŠè¿™ä¸€ç« çš„æ—§ç—•è¿¹æ“¦æ‰
        memory.purge_chapter_memory(link_name)
        print(f"âš¡ [{i + 1}/{len(chapters)}] æ­£åœ¨æ·±åº¦ç ”è¯»ï¼š{curr_safe_title} ...")

        # --- B. AI åˆ†æ ---
        # è·å–ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆTop 20 æ¦‚å¿µï¼‰
        context_str = memory.get_context_string()
        # æ¸²æŸ“ User Prompt
        prompt = get_user_prompt(chap['content'], context_str)

        try:
            # è°ƒç”¨ LLM
            result = call_llm_json(current_system_prompt, prompt)
        except Exception as e:
            print(f"   âš ï¸ åˆ†æå¤±è´¥ï¼Œè·³è¿‡æœ¬ç« : {str(e)}")
            continue

        # --- C. æ›´æ–°çŸ¥è¯†å›¾è°±è®°å¿† ---
        concepts = result.get('key_concepts', [])
        memory.update(concepts, link_name)
        # --- D. ç»„è£… Markdown å†…å®¹ ---
        tags = result.get('tags', [])
        summary = result.get('summary', 'æš‚æ— æ€»ç»“').replace('"', "'")
        # ã€ä¼˜åŒ–ã€‘å°†â€œæ—¶æœŸâ€å’Œâ€œå·â€ä½œä¸ºæ ‡ç­¾åŠ å…¥ï¼Œæ–¹ä¾¿ç­›é€‰
        if period != 'æœªåˆ†ç±»' and period not in tags:
            tags.append(period)
        if volume != 'æœªåˆ†ç±»' and volume not in tags:
            tags.append(volume)
        # è·å–å½“å‰æ—¥æœŸ
        today_date = datetime.date.today().isoformat()
        # æ„å»º Frontmatter (YAML å¤´)
        md_content = f"""---
title: "{curr_safe_title}"
order: {i + 1}
volume: "{volume}"
period: "{period}"
publish_date: "{publish_date}"
tags: {tags}
date: {today_date}
---

# ç¬¬{i + 1}ç«  {curr_safe_title}

> **å½’å±**ï¼š{volume} / {period}
> **å‘è¡¨æ—¶é—´**ï¼š{publish_date}

> **æ‘˜è¦**ï¼š{summary}

"""
        # æ·»åŠ åŸæ–‡æŠ˜å å—
        html_formatted_content = chap['content'].replace('\n', '<br>')
        md_content += f"""
<details>
<summary><strong>ğŸ“„ ç‚¹å‡»å±•å¼€/æ”¶èµ·ï¼šæœ¬ç« åŸæ–‡å…¨æ–‡</strong></summary>

{html_formatted_content}

</details>

"""
        # æ·»åŠ  AI åˆ†ææ­£æ–‡
        md_content += f"""
## ğŸ§  æ·±åº¦æ€è€ƒä¸è§£è¯»

{result.get('analysis')}

"""

        # æ·»åŠ é‡‘å¥
        if 'quotes' in result and result['quotes']:
            md_content += "### ğŸ’¬ æŒ¯è‹å‘è©çš„é‡‘å¥\n"
            for q in result['quotes']:
                md_content += f"> {q}\n>\n"

        md_content += "\n---\n"

        # æ·»åŠ ä¸Šä¸€ç« /ä¸‹ä¸€ç« å¯¼èˆª
        if i > 0:
            prev_chap = chapters[i - 1]
            prev_title = get_safe_title_from_chap(prev_chap)
            prev_link_name = f"{i:03d}_{prev_title}"  # æ³¨æ„è¿™é‡Œåºå·æ ¼å¼ä¿æŒä¸€è‡´
            md_content += f"â¬…ï¸ ä¸Šä¸€ç« ï¼š[[{prev_link_name}]] | "

        if i < len(chapters) - 1:
            next_chap = chapters[i + 1]
            next_title = get_safe_title_from_chap(next_chap)
            next_link_name = f"{i + 2:03d}_{next_title}"
            md_content += f"ä¸‹ä¸€ç« ï¼š[[{next_link_name}]] â¡ï¸"

        # å†™å…¥æ–‡ä»¶
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(md_content)

        # æ›´æ–°ç´¢å¼•è¡¨å­—ç¬¦ä¸²
        tags_str_display = ", ".join([f"`{t}`" for t in tags[:3]])
        link = f"[{curr_safe_title}](./chapters/{file_name})"
        index_content += f"| {i + 1} | {volume} | {period} | {link} | {publish_date} | {tags_str_display} | {summary} |\n"

        # å®æ—¶ä¿å­˜è®°å¿†åˆ°è¿™æœ¬ä¹¦çš„ä¸“ç”¨ç›®å½•
        memory.save_memory(current_kb_dir)

        # =================================================================
        # API å†·å´ç­–ç•¥
        # =================================================================
        if i < len(chapters) - 1:
            sec = 1
            print(f"ğŸ’¤ ä¼‘æ¯ {sec} ç§’ä»¥ä¿æŠ¤ API...")
            wait_with_countdown(sec, "API å†·å´")
        # =================================================================

    # 4. ç»“æŸ
    with open(current_kb_dir / "00_å…¨ä¹¦æ¦‚è§ˆ_Index.md", "w", encoding="utf-8") as f:
        f.write(index_content)

    memory.save_memory(current_kb_dir)
    # ç”Ÿæˆå¡ç‰‡åˆ°ä¸“ç”¨ç›®å½•
    generate_concept_cards(memory, current_kb_dir)

    print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼")
    print("ä½ å¯ä»¥ç›´æ¥ç”¨ Obsidian æ‰“å¼€æ­¤ç›®å½•ï¼Œä½“éªŒæœ€ä½³ã€‚")
