import os
import re
from pathlib import Path

# å¯¼å…¥é…ç½®å’Œæ ¸å¿ƒæ¨¡å—
from ..config import ASSETS_DIR, OUTPUT_DIR
from ..core.loader import read_epub_chapters_custom  # ç¡®ä¿ loader.py é‡Œå‡½æ•°åä¸€è‡´
from ..core.graph_builder import ConceptMemory
from ..core.llm_client import call_llm_json
from .prompt_templates import ANALYSIS_SYSTEM_PROMPT, get_user_prompt

# å®šä¹‰è¾“å‡ºè·¯å¾„
KB_DIR = OUTPUT_DIR / "knowledge_base"
CHAPTERS_DIR = KB_DIR / "chapters"


def sanitize_filename(name):
    """
    ã€å¢å¼ºç‰ˆã€‘æ¸…æ´—æ–‡ä»¶å
    1. ç§»é™¤ html åç¼€
    2. ç§»é™¤ç³»ç»Ÿéæ³•å­—ç¬¦ (/:*?"<>|)
    3. ç§»é™¤ä¸­æ–‡/è‹±æ–‡å¼•å·ï¼Œé˜²æ­¢æ–‡ä»¶åä¸‘é™‹å’Œé“¾æ¥ç ´å
    """
    # ç§»é™¤åç¼€
    name = name.replace('.html', '').replace('.xhtml', '')

    # æ­£åˆ™æ›¿æ¢ï¼šç§»é™¤ \ / * ? : " < > | ä»¥åŠ â€œâ€ â€˜â€™ ' "
    name = re.sub(r'[\\/*?:"<>|â€œâ€â€˜â€™\'"]', "", name)

    # å»é™¤é¦–å°¾ç©ºæ ¼å¹¶æˆªæ–­é•¿åº¦ï¼Œé˜²æ­¢æ–‡ä»¶åè¿‡é•¿
    return name.strip()[:60]


def get_safe_title_from_chap(chapter_data):
    """
    è¾…åŠ©å‡½æ•°ï¼šä»ç« èŠ‚æ•°æ®ä¸­æå–å¹¶æ¸…æ´—æ ‡é¢˜
    ç”¨äºç”Ÿæˆå½“å‰æ–‡ä»¶ã€ä¸Šä¸€ç« é“¾æ¥ã€ä¸‹ä¸€ç« é“¾æ¥ï¼Œç¡®ä¿é€»è¾‘ç»Ÿä¸€
    """
    # ä¼˜å…ˆå– extracted_titleï¼Œå¦‚æœæ²¡æœ‰åˆ™å– id
    raw = chapter_data.get('title', chapter_data['id'])
    return sanitize_filename(raw)


def run_analysis():
    # 1. åˆå§‹åŒ–ç›®å½•
    KB_DIR.mkdir(parents=True, exist_ok=True)
    CHAPTERS_DIR.mkdir(parents=True, exist_ok=True)

    # 2. åŠ è½½ç”µå­ä¹¦
    epub_path = ASSETS_DIR / "æ¯›ä¸»å¸­æ•™æˆ‘ä»¬å½“çœå§”ä¹¦è®°.epub"
    if not epub_path.exists():
        print(f"âŒ é”™è¯¯ï¼šåœ¨ {ASSETS_DIR} ä¸‹æ‰¾ä¸åˆ°ç”µå­ä¹¦æ–‡ä»¶ï¼")
        return

    print("ğŸ“– æ­£åœ¨è§£æç”µå­ä¹¦ç« èŠ‚...")
    # è¿™é‡Œè°ƒç”¨çš„æ˜¯æˆ‘ä»¬ä¹‹å‰ä¿®æ”¹è¿‡çš„ã€èƒ½æå– title çš„ loader
    chapters = read_epub_chapters_custom(epub_path)
    memory = ConceptMemory()

    print(f"ğŸ“š å…±è¯†åˆ«å‡º {len(chapters)} ä¸ªç« èŠ‚ï¼Œå¼€å§‹æ„å»ºçŸ¥è¯†åº“...\n")

    # åˆå§‹åŒ–æ€»ç´¢å¼•å†…å®¹
    index_content = "# å…¨ä¹¦ç›®å½•ä¸ç´¢å¼•\n\n| åºå· | ç« èŠ‚ | æ ¸å¿ƒæ ‡ç­¾ | ä¸€å¥è¯æ€»ç»“ |\n|---|---|---|---|\n"

    # 3. é€ç« å¤„ç†
    for i, chap in enumerate(chapters):

        # --- A. å‡†å¤‡æ–‡ä»¶å ---
        # è·å–æ¸…æ´—åçš„æ ‡é¢˜
        curr_safe_title = get_safe_title_from_chap(chap)

        # ç”Ÿæˆå¸¦åºå·çš„æ–‡ä»¶åï¼Œå¦‚ "01_çœå§”ç¬¬ä¸€ä¹¦è®°è¦æŠ“ç†è®ºå·¥ä½œ.md"
        file_name = f"{i + 1:02d}_{curr_safe_title}.md"
        file_path = CHAPTERS_DIR / file_name

        print(f"âš¡ [{i + 1}/{len(chapters)}] æ­£åœ¨æ·±åº¦ç ”è¯»ï¼š{curr_safe_title} ...")

        # --- B. AI åˆ†æ (RAG + è®°å¿†) ---
        context_str = memory.get_context_string()
        prompt = get_user_prompt(chap['content'], context_str)

        try:
            # è°ƒç”¨å¤§æ¨¡å‹è·å– JSON
            result = call_llm_json(ANALYSIS_SYSTEM_PROMPT, prompt)
        except Exception as e:
            print(f"   âš ï¸ åˆ†æå¤±è´¥ï¼Œè·³è¿‡æœ¬ç« : {str(e)}")
            continue

        # --- C. æ›´æ–°çŸ¥è¯†å›¾è°±è®°å¿† (å¯é€‰) ---
        concepts = result.get('key_concepts', [])
        memory.update(concepts, curr_safe_title)
        # --- D. ç»„è£… Markdown å†…å®¹ ---

        # 1. Frontmatter (å…ƒæ•°æ®)
        tags = result.get('tags', [])
        # å¤„ç†æ‘˜è¦ä¸­çš„åŒå¼•å·ï¼Œé˜²æ­¢ YAML æ ¼å¼é”™è¯¯
        summary = result.get('summary', 'æš‚æ— æ€»ç»“').replace('"', "'")

        md_content = f"""---
title: "{curr_safe_title}"
order: {i + 1}
tags: {tags}
date: 2025-11-30
---

# ç¬¬{i + 1}ç«  {curr_safe_title}

> **æ‘˜è¦**ï¼š{summary}

"""
        # 2. åŸæ–‡å…¨æ–‡ (æŠ˜å æ˜¾ç¤º)
        # æ³¨æ„ï¼š<details> å†…éƒ¨ä¿ç•™ç©ºè¡Œï¼Œä»¥ç¡®ä¿ Markdown æ¸²æŸ“æ­£å¸¸
        md_content += f"""
<details>
<summary><strong>ğŸ“„ ç‚¹å‡»å±•å¼€/æ”¶èµ·ï¼šæœ¬ç« åŸæ–‡å…¨æ–‡</strong></summary>

{chap['content']}

</details>

"""

        # 3. æ·±åº¦æ€è€ƒ (Analysis)
        md_content += f"""
## ğŸ§  æ·±åº¦æ€è€ƒä¸è§£è¯»

{result.get('analysis')}

"""

        # 4. é‡‘å¥æ‘˜å½• (Quotes)
        if 'quotes' in result and result['quotes']:
            md_content += "### ğŸ’¬ æŒ¯è‹å‘è©çš„é‡‘å¥\n"
            for q in result['quotes']:
                md_content += f"> {q}\n>\n"

        # 5. åº•éƒ¨å¯¼èˆª (å…³é”®ä¿®å¤ï¼šç¡®ä¿é“¾æ¥æ–‡ä»¶åä¸ç”Ÿæˆçš„ä¸€è‡´)
        md_content += "\n---\n"

        # ä¸Šä¸€ç« 
        if i > 0:
            prev_chap = chapters[i - 1]
            prev_title = get_safe_title_from_chap(prev_chap)
            # åºå·è§„åˆ™ï¼šä¸Šä¸€ç« çš„ç´¢å¼•æ˜¯ i-1ï¼Œæ‰€ä»¥å®ƒçš„åºå·æ˜¯ (i-1)+1 = i
            prev_link_name = f"{i:02d}_{prev_title}"
            md_content += f"â¬…ï¸ ä¸Šä¸€ç« ï¼š[[{prev_link_name}]] | "

        # ä¸‹ä¸€ç« 
        if i < len(chapters) - 1:
            next_chap = chapters[i + 1]
            next_title = get_safe_title_from_chap(next_chap)
            # åºå·è§„åˆ™ï¼šä¸‹ä¸€ç« çš„ç´¢å¼•æ˜¯ i+1ï¼Œæ‰€ä»¥å®ƒçš„åºå·æ˜¯ (i+1)+1 = i+2
            next_link_name = f"{i + 2:02d}_{next_title}"
            md_content += f"ä¸‹ä¸€ç« ï¼š[[{next_link_name}]] â¡ï¸"

        # --- E. å†™å…¥æ–‡ä»¶ ---
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(md_content)

        # --- F. æ›´æ–°ç›®å½•ç´¢å¼• ---
        tags_str = ", ".join([f"`{t}`" for t in tags[:3]])  # åªå±•ç¤ºå‰3ä¸ªæ ‡ç­¾
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„é“¾æ¥ï¼Œæ–¹ä¾¿åœ¨ GitHub æˆ– Obsidian ä¸­ç›´æ¥ç‚¹å‡»
        link = f"[{curr_safe_title}](./chapters/{file_name})"
        index_content += f"| {i + 1} | {link} | {tags_str} | {summary} |\n"

    # 4. å¾ªç¯ç»“æŸåçš„æ”¶å°¾å·¥ä½œ

    # A. å†™å…¥æ€»ç´¢å¼•
    with open(KB_DIR / "00_å…¨ä¹¦æ¦‚è§ˆ_Index.md", "w", encoding="utf-8") as f:
        f.write(index_content)

    # B. ã€æ–°å¢ã€‘ä¿å­˜çŸ¥è¯†å›¾è°±æ•°æ®
    memory.save_memory(KB_DIR)
    print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼çŸ¥è¯†åº“å·²ç”Ÿæˆåœ¨ï¼š{KB_DIR}")
    print("ä½ å¯ä»¥ç›´æ¥ç”¨ Obsidian æ‰“å¼€æ­¤ç›®å½•ï¼Œä½“éªŒæœ€ä½³ã€‚")
