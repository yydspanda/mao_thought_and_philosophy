import re
import time
import sys
from pathlib import Path

# ä¿æŒåŸæœ‰çš„å¯¼å…¥ä¸å˜
from .prompt_templates import get_user_prompt, get_system_prompt
from ..config import ASSETS_DIR, OUTPUT_DIR
from ..core.graph_builder import ConceptMemory
from ..core.llm_client import call_llm_json
from ..core.loader import read_epub_chapters_custom

# å®šä¹‰è¾“å‡ºè·¯å¾„
KB_DIR = OUTPUT_DIR / "knowledge_base"
CHAPTERS_DIR = KB_DIR / "chapters"
CONCEPTS_DIR = KB_DIR / "concepts"


def sanitize_filename(name):
    """ã€å¢å¼ºç‰ˆã€‘æ¸…æ´—æ–‡ä»¶å"""
    name = name.replace('.html', '').replace('.xhtml', '')
    name = re.sub(r'[\\/*?:"<>|â€œâ€â€˜â€™\'"]', "", name)
    return name.strip()[:60]


def get_safe_title_from_chap(chapter_data):
    """è¾…åŠ©å‡½æ•°ï¼šä»ç« èŠ‚æ•°æ®ä¸­æå–å¹¶æ¸…æ´—æ ‡é¢˜"""
    raw = chapter_data.get('title', chapter_data['id'])
    return sanitize_filename(raw)


def wait_with_countdown(seconds, message="ç­‰å¾…ä¸­"):
    """
    å€’è®¡æ—¶è¾…åŠ©å‡½æ•°
    æ˜¾ç¤ºæ ¼å¼ï¼šâ³ ç­‰å¾…ä¸­: 00:29:59 ...
    """
    print(f"\nğŸ›‘ {message} (å…± {seconds / 60:.1f} åˆ†é’Ÿ)...")
    for remaining in range(seconds, 0, -1):
        mins, secs = divmod(remaining, 60)
        hours, mins = divmod(mins, 60)
        time_format = f"{hours:02d}:{mins:02d}:{secs:02d}"

        # ä½¿ç”¨ \r å›è½¦ç¬¦å®ç°å•è¡Œåˆ·æ–°ï¼Œä¸æ¢è¡Œ
        sys.stdout.write(f"\râ³ å€’è®¡æ—¶: {time_format}")
        sys.stdout.flush()
        time.sleep(1)
    print("\nâœ… ç­‰å¾…ç»“æŸï¼Œç»§ç»­æ‰§è¡Œï¼\n")


def generate_concept_cards(memory):
    """å°† JSON æ•°æ®è½¬åŒ–ä¸º Obsidian å¯è¯»çš„ Markdown æ¦‚å¿µå¡ç‰‡"""
    CONCEPTS_DIR.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ“‡ æ­£åœ¨ç”Ÿæˆ {len(memory.concepts)} å¼ æ¦‚å¿µå¡ç‰‡...")

    for name, definition in memory.concepts.items():
        safe_name = sanitize_filename(name)
        if not safe_name: continue

        file_path = CONCEPTS_DIR / f"{safe_name}.md"
        chapter_links = memory.appearances.get(name, [])
        backlinks = ", ".join([f"[[{link}]]" for link in chapter_links])

        content = f"""---
tags: [æ ¸å¿ƒæ¦‚å¿µ]
---

# {name}

### ğŸ“ å®šä¹‰
> {definition}

### ğŸ“š å‡ºç°ç« èŠ‚
{backlinks}
"""
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)

    print(f"âœ… æ¦‚å¿µå¡ç‰‡å·²ç”Ÿæˆè‡³: {CONCEPTS_DIR}")


def run_analysis():
    # 1. åˆå§‹åŒ–ç›®å½•
    KB_DIR.mkdir(parents=True, exist_ok=True)
    CHAPTERS_DIR.mkdir(parents=True, exist_ok=True)

    # 2. åŠ è½½ç”µå­ä¹¦
    epub_path = ASSETS_DIR / "æ¯›ä¸»å¸­æ•™æˆ‘ä»¬å½“çœå§”ä¹¦è®°.epub"
    if not epub_path.exists():
        print(f"âŒ é”™è¯¯ï¼šåœ¨ {ASSETS_DIR} ä¸‹æ‰¾ä¸åˆ°ç”µå­ä¹¦æ–‡ä»¶ï¼")
        return

    book_title = epub_path.stem
    print(f"ğŸ“– æ­£åœ¨è§£æã€Š{book_title}ã€‹...")

    current_system_prompt = get_system_prompt(book_title)
    chapters = read_epub_chapters_custom(epub_path)

    memory = ConceptMemory()
    json_path = KB_DIR / "knowledge_graph.json"
    memory.load_from_file(json_path)

    print(f"ğŸ“š å…±è¯†åˆ«å‡º {len(chapters)} ä¸ªç« èŠ‚ã€‚")

    # =================================================================
    # ã€æ–°å¢é€»è¾‘ 1ã€‘å¯åŠ¨æ—¶å¼ºåˆ¶ç­‰å¾… 1 å°æ—¶ (3600ç§’)
    # åªæœ‰å½“ç¡®å®æœ‰ä»»åŠ¡è¦è·‘æ—¶æ‰ç­‰å¾…ï¼Œè¿™é‡Œç®€å•å¤„ç†ï¼Œç›´æ¥ç­‰
    # =================================================================
    print("ğŸš¦ ä¾æ®ç­–ç•¥ï¼Œç¨‹åºå°†åœ¨ 1 å°æ—¶åå¼€å§‹å¤„ç†...")
    # wait_with_countdown(3600, "å¯åŠ¨å»¶è¿Ÿ")
    # æµ‹è¯•æ—¶å¯ä»¥æŠŠä¸Šé¢æ”¹æˆ wait_with_countdown(5, "å¯åŠ¨å»¶è¿Ÿ") çœ‹æ•ˆæœ

    index_content = "# å…¨ä¹¦ç›®å½•ä¸ç´¢å¼•\n\n| åºå· | ç« èŠ‚ | æ ¸å¿ƒæ ‡ç­¾ | ä¸€å¥è¯æ€»ç»“ |\n|---|---|---|---|\n"

    # 3. é€ç« å¤„ç†
    for i, chap in enumerate(chapters):

        curr_safe_title = get_safe_title_from_chap(chap)
        file_name = f"{i + 1:02d}_{curr_safe_title}.md"
        file_path = CHAPTERS_DIR / file_name
        link_name = f"{i + 1:02d}_{curr_safe_title}"

        # =================================================================
        # æ–­ç‚¹ç»­ä¼ ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        # =================================================================
        if file_path.exists():
            print(f"â© [å·²å­˜åœ¨ï¼Œè·³è¿‡] {file_name}")
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    summary_match = re.search(r'> \*\*æ‘˜è¦\*\*ï¼š(.*?)\n', content)
                    summary = summary_match.group(1).strip() if summary_match else "ï¼ˆæ‘˜è¦è¯»å–å¤±è´¥ï¼‰"
                    tags_match = re.search(r'tags: \[(.*?)\]', content)
                    tags_str = tags_match.group(1) if tags_match else ""
                    tags_clean = tags_str.replace("'", "").replace('"', "")
                    tags_display = ", ".join([f"`{t.strip()}`" for t in tags_clean.split(',')][:3])
                    link = f"[{curr_safe_title}](./chapters/{file_name})"
                    index_content += f"| {i + 1} | {link} | {tags_display} | {summary} |\n"
            except Exception:
                pass
            continue  # è·³è¿‡ï¼Œä¸”ä¸è¿›è¡Œç­‰å¾…
        # =================================================================

        print(f"âš¡ [{i + 1}/{len(chapters)}] æ­£åœ¨æ·±åº¦ç ”è¯»ï¼š{curr_safe_title} ...")

        # --- B. AI åˆ†æ ---
        context_str = memory.get_context_string()
        prompt = get_user_prompt(chap['content'], context_str)

        try:
            result = call_llm_json(current_system_prompt, prompt)
        except Exception as e:
            print(f"   âš ï¸ åˆ†æå¤±è´¥ï¼Œè·³è¿‡æœ¬ç« : {str(e)}")
            continue

        # --- C. æ›´æ–°çŸ¥è¯†å›¾è°±è®°å¿† ---
        concepts = result.get('key_concepts', [])
        memory.update(concepts, link_name)

        # --- D. ç»„è£… Markdown å†…å®¹ ---
        tags = result.get('tags', [])
        summary = result.get('summary', 'æš‚æ— æ€»ç»“').replace('"', "'")

        md_content = f"""---
title: "{curr_safe_title}"
order: {i + 1}
tags: {tags}kl
date: 2025-11-30
---

# ç¬¬{i + 1}ç«  {curr_safe_title}

> **æ‘˜è¦**ï¼š{summary}

"""
        html_formatted_content = chap['content'].replace('\n', '<br>')
        md_content += f"""
<details>
<summary><strong>ğŸ“„ ç‚¹å‡»å±•å¼€/æ”¶èµ·ï¼šæœ¬ç« åŸæ–‡å…¨æ–‡</strong></summary>

{html_formatted_content}

</details>

"""
        md_content += f"""
## ğŸ§  æ·±åº¦æ€è€ƒä¸è§£è¯»

{result.get('analysis')}

"""

        if 'quotes' in result and result['quotes']:
            md_content += "### ğŸ’¬ æŒ¯è‹å‘è©çš„é‡‘å¥\n"
            for q in result['quotes']:
                md_content += f"> {q}\n>\n"

        md_content += "\n---\n"

        if i > 0:
            prev_chap = chapters[i - 1]
            prev_title = get_safe_title_from_chap(prev_chap)
            prev_link_name = f"{i:02d}_{prev_title}"
            md_content += f"â¬…ï¸ ä¸Šä¸€ç« ï¼š[[{prev_link_name}]] | "

        if i < len(chapters) - 1:
            next_chap = chapters[i + 1]
            next_title = get_safe_title_from_chap(next_chap)
            next_link_name = f"{i + 2:02d}_{next_title}"
            md_content += f"ä¸‹ä¸€ç« ï¼š[[{next_link_name}]] â¡ï¸"

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(md_content)

        tags_str = ", ".join([f"`{t}`" for t in tags[:3]])
        link = f"[{curr_safe_title}](./chapters/{file_name})"
        index_content += f"| {i + 1} | {link} | {tags_str} | {summary} |\n"

        # å®æ—¶ä¿å­˜è®°å¿†ï¼Œé˜²æ­¢ä¸­æ–­
        memory.save_memory(KB_DIR)

        # =================================================================
        # ã€æ–°å¢é€»è¾‘ 2ã€‘ç« èŠ‚é—´æ­‡æœŸç­‰å¾… 30 åˆ†é’Ÿ (1800ç§’)
        # =================================================================
        # åªæœ‰å½“ä¸æ˜¯æœ€åä¸€ç« æ—¶æ‰ç­‰å¾…
        # if i < len(chapters) - 1:
        #     print("ğŸ’¤ æœ¬ç« å¤„ç†å®Œæ¯•ï¼Œä¼‘æ¯ 30 åˆ†é’Ÿä»¥æ¢å¤ API é¢åº¦...")
        #     wait_with_countdown(1800, "API å†·å´ä¸­")
            # æµ‹è¯•æ—¶å¯ä»¥æŠŠä¸Šé¢æ”¹æˆ wait_with_countdown(5, "API å†·å´ä¸­")
        # =================================================================

    # 4. å¾ªç¯ç»“æŸ
    with open(KB_DIR / "00_å…¨ä¹¦æ¦‚è§ˆ_Index.md", "w", encoding="utf-8") as f:
        f.write(index_content)

    memory.save_memory(KB_DIR)
    generate_concept_cards(memory)

    print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼çŸ¥è¯†åº“å·²ç”Ÿæˆåœ¨ï¼š{KB_DIR}")
    print("ä½ å¯ä»¥ç›´æ¥ç”¨ Obsidian æ‰“å¼€æ­¤ç›®å½•ï¼Œä½“éªŒæœ€ä½³ã€‚")