import re
from typing import Any, Dict

from json_repair import repair_json  # ã€æ–°å¢ã€‘å¼•å…¥ä¿®å¤åº“
from openai import OpenAI

from ..config import LLM_API_KEY, LLM_BASE_URL, LLM_MODEL


def _clean_json_string(json_str: str) -> str:
    """æ¸…æ´— JSON å­—ç¬¦ä¸²ï¼Œç§»é™¤ Markdown ä»£ç å—æ ‡è®°"""
    pattern = r"^```(?:json)?\s*(.*?)\s*```$"
    match = re.search(pattern, json_str, re.DOTALL)
    if match:
        return match.group(1)
    return json_str.strip()


def call_llm_json(system_prompt: str, user_prompt: str) -> Dict[str, Any]:
    """
    è°ƒç”¨å¤§æ¨¡å‹å¹¶å¼ºåˆ¶è¿”å› Python å­—å…¸ (JSON)ã€‚
    é›†æˆ json_repair ä»¥å¢å¼ºå¯¹å¤§æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯çš„å®¹é”™èƒ½åŠ›ã€‚
    """
    # åœ¨è¿™é‡Œä¿ç•™ç®€å•çš„é˜²å¾¡æ€§æ£€æŸ¥
    if not LLM_API_KEY:
        raise ValueError("LLM_API_KEY æœªé…ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

    # ç›´æ¥ä½¿ç”¨ config ä¸­å¯¼å…¥çš„å˜é‡
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)

    content: str = ""  # åˆå§‹åŒ–å˜é‡ï¼Œé˜²æ­¢åœ¨ try å—ä¹‹å‰æŠ¥é”™å¯¼è‡´ except è®¿é—®ä¸åˆ°

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            # å¼ºåˆ¶æ¨¡å‹å°è¯•è¾“å‡º JSON ç»“æ„
            response_format={"type": "json_object"},
            temperature=0.3,
        )

        raw_content = response.choices[0].message.content
        content = raw_content if raw_content is not None else ""
        cleaned_content = _clean_json_string(content)

        # return_objects=True è¡¨ç¤ºç›´æ¥è¿”å› Python å­—å…¸/åˆ—è¡¨
        # å®ƒå¯ä»¥è‡ªåŠ¨ä¿®å¤ï¼šæœªè½¬ä¹‰çš„å¼•å·ã€ç¼ºå°‘çš„é—­åˆæ‹¬å·ã€å¤šä½™çš„é€—å·ç­‰
        parsed_data = repair_json(cleaned_content, return_objects=True)

        if not isinstance(parsed_data, dict):
            raise TypeError(
                f"LLM did not return a JSON object as expected. Got type {type(parsed_data)}."
            )

        return parsed_data

    except Exception as e:
        print(f"\nâŒ API è°ƒç”¨æˆ– JSON è§£æé”™è¯¯: {str(e)}")

        # ã€æ–°å¢ã€‘æ‰“å°å¯¼è‡´é”™è¯¯çš„åŸå§‹å†…å®¹ç‰‡æ®µï¼Œæ–¹ä¾¿è°ƒè¯•
        print("ğŸ” å¯¼è‡´é”™è¯¯çš„åŸå§‹å†…å®¹ (å‰500å­—ç¬¦):")
        print(content[:500] + "...")

        # æŠ›å‡ºå¼‚å¸¸è®© workflow å¤„ç†
        raise e


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç ï¼šä¿®æ”¹ä¸ºæ˜ç¡®è¦æ±‚ JSON çš„æç¤ºè¯ï¼Œå¦åˆ™ response_format å¯èƒ½æŠ¥é”™
    sys_prompt = "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œè¯·åŠ¡å¿…åªè¾“å‡º JSON æ ¼å¼ã€‚"
    user_prompt = "å’Œå¤§å®¶æ‰“ä¸ªç¾å›½å¼çš„æ‹›å‘¼ï¼Œè¿”å›å­—æ®µ {'greeting': 'å†…å®¹'}"

    try:
        result = call_llm_json(sys_prompt, user_prompt)
        print("æµ‹è¯•æˆåŠŸ:", result)
    except Exception as e:
        print("æµ‹è¯•å¤±è´¥:", e)
